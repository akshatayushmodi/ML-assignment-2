{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7827744,"sourceType":"datasetVersion","datasetId":4587165}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\ndata = pd.read_csv('/kaggle/input/plastic/plastic (1).csv')\ndata.dropna(inplace=True)\none_hot_cols=['Gender', 'Residence', 'Occupation', 'location_of_usage', 'dispose_outdoor', 'waste_around_you', 'disposal_behaviour', 'awareness_source', 'way_to_reduce', 'alternatives']\nage_order= ['Young', 'Middle Aged', 'Old']\nedu_order= ['Nothing', 'School', 'College', 'University']\nagree_order= ['Strongly Disagree', 'Disagree', 'Neutral', 'Agree', 'Strongly Agree']\ntime_deg_ord= ['days50', '50 years', 'Donâ€™t know', '500 years', 'Never degrade']\naware_symb_ord= ['I never saw it', 'No', 'Yes']\nfreq_order= ['Always',  'Usually','Often', 'Sometimes', 'Never']\nreuse_order= ['Didnâ€™t reuse', 'Donâ€™t reuse', 'One time', 'more than 5','Few weeks', 'Few months', '2-1 years']\nyn_order= ['No', 'Yes']\nneg_order= [\"I don't think about the negative impact of plastic\", \"I think about negative impact of plastic but I buy it anyways\" , \"I think about the negative impact of the plastic and sometimes I don not buy it\", \"I think about negative impact and look for the alternative\"]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T11:10:52.221686Z","iopub.execute_input":"2024-03-16T11:10:52.222558Z","iopub.status.idle":"2024-03-16T11:10:53.426317Z","shell.execute_reply.started":"2024-03-16T11:10:52.222508Z","shell.execute_reply":"2024-03-16T11:10:53.424767Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nencoded_df = data.copy()\n\nordinal_encoder = OrdinalEncoder(categories=[age_order, edu_order, agree_order, time_deg_ord, aware_symb_ord, agree_order, agree_order, agree_order, reuse_order, freq_order, reuse_order, freq_order, freq_order, freq_order, freq_order, freq_order, yn_order, yn_order, agree_order, agree_order, neg_order])\nordinal_encoded = ordinal_encoder.fit_transform(data[['Age', 'Education', 'Environmental_affect', 'Time_to_degrade', 'Recycling_symbol', 'Microplastic_in_food', 'Chemical_absorbtion', 'Recycle_plastic',  'bag_reuse', 'takeyourbag', 'bottle_reuse', 'cleaning_responsibility', 'plastic_over_other', 'ensure_biodegradable', 'microwavesafe', 'food_in_bag', 'special_bins', 'teaching_kids', 'willing_to_adopt', 'survival_without_plastic', 'negative_impact' ]])\nordinal_encoded_df = pd.DataFrame(ordinal_encoded, columns=['Age', 'Education', 'Environmental_affect', 'Time_to_degrade', 'Recycling_symbol', 'Microplastic_in_food', 'Chemical_absorbtion', 'Recycle_plastic', 'bag_reuse', 'takeyourbag', 'bottle_reuse', 'cleaning_responsibility', 'plastic_over_other', 'ensure_biodegradable' , 'microwavesafe', 'food_in_bag', 'special_bins', 'teaching_kids', 'willing_to_adopt', 'survival_without_plastic', 'negative_impact'])\n\n# Perform one-hot encoding for remaining columns\none_hot_encoded = pd.get_dummies(data[one_hot_cols], drop_first=True)\none_hot_encoded= one_hot_encoded.astype(float)\n\n# Combine one-hot encoded and ordinal encoded dataframes with the original dataframe\nencoded_df = pd.concat([one_hot_encoded, ordinal_encoded_df], axis=1)\n\n# for cols in encoded_df.columns:\n#     print(type(encoded_df[cols][0]))\n# print(encoded_df.head())\nencoded_df=encoded_df.dropna()\n# encoded_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T11:10:53.428645Z","iopub.execute_input":"2024-03-16T11:10:53.429033Z","iopub.status.idle":"2024-03-16T11:10:53.483475Z","shell.execute_reply.started":"2024-03-16T11:10:53.429000Z","shell.execute_reply":"2024-03-16T11:10:53.482100Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"y_columns = ['survival_without_plastic', 'Time_to_degrade', 'cleaning_responsibility', 'negative_impact', 'teaching_kids']\nX_columns = [col for col in encoded_df.columns if col not in y_columns]\ny=encoded_df[y_columns]\nX=encoded_df[X_columns]\n# Convert NumPy arrays to pandas DataFrame\n# y = pd.DataFrame(data=y, columns=y_columns)\n# X = pd.DataFrame(data=X, columns=X_columns)\n\n# X.dropna(inplace=True)\n# y.dropna(inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)#data split to train and test \n\nprint(\"Shape: \", X.shape, \"Dimension: \", X.ndim)\nprint(\"Shape: \", y.shape, \"Dimension: \", y.ndim)\n# y","metadata":{"execution":{"iopub.status.busy":"2024-03-16T11:10:53.485411Z","iopub.execute_input":"2024-03-16T11:10:53.485813Z","iopub.status.idle":"2024-03-16T11:10:53.503674Z","shell.execute_reply.started":"2024-03-16T11:10:53.485761Z","shell.execute_reply":"2024-03-16T11:10:53.501867Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Shape:  (223, 56) Dimension:  2\nShape:  (223, 5) Dimension:  2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the MultiClassLogisticRegression class\nclass MultiClassLogisticRegression:\n   \n    def __init__(self, n_iter=10000, thres=1e-3):\n        self.n_iter = n_iter\n        self.thres = thres\n        self.eps= 1e-9\n   \n    def fit(self, X, y, batch_size=64, lr=0.001, rand_seed=4, verbose=False):\n        np.random.seed(rand_seed)\n        self.classes = np.unique(y)\n        self.class_labels = {c:i for i,c in enumerate(self.classes)}\n        X = self.add_bias(X)\n        y = self.one_hot(y)\n        self.loss = []\n        self.weights = np.zeros(shape=(len(self.classes),X.shape[1]))\n        self.fit_data(X, y, batch_size, lr, verbose)\n        return self\n \n    def fit_data(self, X, y, batch_size, lr, verbose):\n        i = 0\n        while (not self.n_iter or i < self.n_iter):\n            self.loss.append(self.cross_entropy(y, self.predict_(X)))\n            idx = np.random.choice(X.shape[0], batch_size)\n            X_batch, y_batch = X[idx], y[idx]\n            error = y_batch - self.predict_(X_batch)\n            update = (lr * np.dot(error.T, X_batch))\n            self.weights += update\n            if np.abs(update).max() < self.thres: break\n            if i % 1000 == 0 and verbose:\n                print(' Training Accuray at {} iterations is {}'.format(i, self.evaluate_(X, y)))\n            i += 1\n   \n    def predict(self, X):\n        return self.predict_(self.add_bias(X))\n   \n    def predict_(self, X):\n        pre_vals = np.dot(X, self.weights.T).reshape(-1,len(self.classes))\n        return self.softmax(pre_vals)\n   \n    def softmax(self, z):\n        return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n   \n    def predict_classes(self, X):\n        self.probs_ = self.predict(X)\n        return np.vectorize(lambda c: self.classes[c])(np.argmax(self.probs_, axis=1))\n \n    def add_bias(self, X):\n        return np.insert(X, 0, 1, axis=1)\n \n    def one_hot(self, y):\n        return np.eye(len(self.classes))[np.vectorize(lambda c: self.class_labels[c])(y).reshape(-1)]\n   \n    def score(self, X, y):\n        return np.mean(self.predict_classes(X) == y)\n   \n    def evaluate_(self, X, y):\n        return np.mean(np.argmax(self.predict_(X), axis=1) == np.argmax(y, axis=1))\n   \n    def cross_entropy(self, y, probs):\n        return -1 * np.mean(y * np.log(probs+self.eps))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T11:10:53.506420Z","iopub.execute_input":"2024-03-16T11:10:53.506871Z","iopub.status.idle":"2024-03-16T11:10:53.530614Z","shell.execute_reply.started":"2024-03-16T11:10:53.506822Z","shell.execute_reply":"2024-03-16T11:10:53.529333Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n# Define the hyperparameters grid\nlr_values = [0.001, 0.01, 0.1]\nn_iter_values = [1000, 5000, 10000, 20000]\nbatch_size_values = [8, 16, 32, 64]\n\nX_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n\n# Perform grid search\n\nfor col in ['survival_without_plastic', 'Time_to_degrade', 'cleaning_responsibility', 'negative_impact', 'teaching_kids']:\n    best_accuracy = 0\n    best_params = {}\n    for lr in lr_values:\n        for n_iter in n_iter_values:\n            for batch_size in batch_size_values:\n                print(\"Training with parameters - lr: {}, n_iter: {}, batch_size: {}\".format(lr, n_iter, batch_size))\n                multiclass_logreg = MultiClassLogisticRegression(n_iter=n_iter, thres=1e-3)\n                multiclass_logreg.fit(X_train_1, y_train_1[col], batch_size=batch_size, lr=lr)\n                y_pred = multiclass_logreg.predict_classes(X_train_2)\n                accuracy = accuracy_score(y_train_2[col], y_pred)\n                print(\"Accuracy:\", accuracy)\n                if accuracy > best_accuracy:\n                    best_accuracy = accuracy\n                    best_params = {'lr': lr, 'n_iter': n_iter, 'batch_size': batch_size}\n                    \n    multiclass_logreg = MultiClassLogisticRegression(n_iter=best_params['n_iter'], thres=1e-3)\n    multiclass_logreg.fit(X_train, y_train[col], batch_size=best_params['batch_size'], lr=best_params['lr'])\n    y_pred = multiclass_logreg.predict_classes(X_test)\n    accuracy = accuracy_score(y_test[col], y_pred)\n    y_true=y_test[col]\n    precision = precision_score(y_true, y_pred, average='weighted')  # Use 'weighted' if you have multiclass classification\n\n    # Recall\n    recall = recall_score(y_true, y_pred, average='weighted')  # Use 'weighted' if you have multiclass classification\n\n    # F1-score\n    f1 = f1_score(y_true, y_pred, average='weighted')  # Use 'weighted' if you have multiclass classification\n\n    print(\"\\nAccuracy:\", accuracy)\n    print(\"Precision:\", precision)\n    print(\"Recall:\", recall)\n    print(\"F1-score:\", f1)\n    \n    print(\"\\nBest parameters:\", best_params)\n#     print(\"Best accuracy:\", best_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T11:10:53.532713Z","iopub.execute_input":"2024-03-16T11:10:53.533579Z","iopub.status.idle":"2024-03-16T11:14:47.640664Z","shell.execute_reply.started":"2024-03-16T11:10:53.533540Z","shell.execute_reply":"2024-03-16T11:14:47.639026Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Training with parameters - lr: 0.001, n_iter: 1000, batch_size: 8\nAccuracy: 0.5370370370370371\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 16\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 32\nAccuracy: 0.5185185185185185\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 64\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 8\nAccuracy: 0.5370370370370371\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 16\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 32\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 64\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 8\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 16\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 32\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 64\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 8\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 32\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 64\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 8\nAccuracy: 0.5555555555555556\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 16\nAccuracy: 0.5740740740740741\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 32\nAccuracy: 0.5555555555555556\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 64\nAccuracy: 0.2777777777777778\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 8\nAccuracy: 0.5185185185185185\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 32\nAccuracy: 0.5740740740740741\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 64\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 8\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 16\nAccuracy: 0.48148148148148145\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 64\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 8\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 64\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 16\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 32\nAccuracy: 0.5740740740740741\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.037037037037037035\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 16\nAccuracy: 0.5\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.037037037037037035\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 16\nAccuracy: 0.5\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.037037037037037035\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 16\nAccuracy: 0.5\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.037037037037037035\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.5555555555555556\nPrecision: 0.4844444444444444\nRecall: 0.5555555555555556\nF1-score: 0.45444444444444443\n\nAccuracy: 0.5555555555555556 \n\n\nBest parameters: {'lr': 0.1, 'n_iter': 1000, 'batch_size': 16}\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 8\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 32\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 64\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 64\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 16\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 32\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 64\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 64\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 16\nAccuracy: 0.25925925925925924\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 32\nAccuracy: 0.3148148148148148\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 64\nAccuracy: 0.3148148148148148\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 32\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 64\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 16\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 32\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 64\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 64\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 64\nAccuracy: 0.24074074074074073\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 64\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 64\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 64\nAccuracy: 0.3888888888888889\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.4888888888888889\nPrecision: 0.48644122383252814\nRecall: 0.4888888888888889\nF1-score: 0.4584536791433343\n\nAccuracy: 0.4888888888888889 \n\n\nBest parameters: {'lr': 0.001, 'n_iter': 1000, 'batch_size': 8}\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 8\nAccuracy: 0.5555555555555556\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 16\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 32\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 64\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 8\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 16\nAccuracy: 0.48148148148148145\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 32\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 64\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 8\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 16\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 32\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 64\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 8\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 16\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 32\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 64\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 16\nAccuracy: 0.4444444444444444\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 32\nAccuracy: 0.48148148148148145\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 64\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 16\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 32\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 64\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 16\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 32\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 64\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 16\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 32\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 64\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 16\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6111111111111112\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 16\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6111111111111112\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 16\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6111111111111112\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 8\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 16\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6111111111111112\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: overflow encountered in exp\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/tmp/ipykernel_33/1167906343.py:42: RuntimeWarning: invalid value encountered in divide\n  return np.exp(z) / (np.sum(np.exp(z), axis=1).reshape(-1,1) + self.eps)\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6444444444444445\nPrecision: 0.41530864197530865\nRecall: 0.6444444444444445\nF1-score: 0.5051051051051052\n\nAccuracy: 0.6444444444444445 \n\n\nBest parameters: {'lr': 0.1, 'n_iter': 1000, 'batch_size': 64}\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 8\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 64\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 8\nAccuracy: 0.42592592592592593\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 32\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 64\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 16\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 32\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 64\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 8\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 16\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 64\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 8\nAccuracy: 0.2962962962962963\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 16\nAccuracy: 0.3333333333333333\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 32\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 64\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 8\nAccuracy: 0.46296296296296297\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 16\nAccuracy: 0.3333333333333333\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 32\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 64\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 16\nAccuracy: 0.2777777777777778\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 32\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 64\nAccuracy: 0.2962962962962963\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 16\nAccuracy: 0.3148148148148148\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 32\nAccuracy: 0.2962962962962963\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 64\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 32\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 64\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 64\nAccuracy: 0.37037037037037035\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 64\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 8\nAccuracy: 0.4074074074074074\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 16\nAccuracy: 0.3888888888888889\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 32\nAccuracy: 0.35185185185185186\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 64\nAccuracy: 0.35185185185185186\nAccuracy: 0.5111111111111111\nPrecision: 0.49032258064516127\nRecall: 0.5111111111111111\nF1-score: 0.4691823899371069\n\nAccuracy: 0.5111111111111111 \n\n\nBest parameters: {'lr': 0.001, 'n_iter': 1000, 'batch_size': 64}\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 8\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 16\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 32\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.001, n_iter: 1000, batch_size: 64\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 8\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 16\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 32\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.001, n_iter: 5000, batch_size: 64\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 8\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 16\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 32\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.001, n_iter: 10000, batch_size: 64\nAccuracy: 0.6111111111111112\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 8\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 16\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 32\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.001, n_iter: 20000, batch_size: 64\nAccuracy: 0.6111111111111112\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 8\nAccuracy: 0.7222222222222222\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 16\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 32\nAccuracy: 0.5740740740740741\nTraining with parameters - lr: 0.01, n_iter: 1000, batch_size: 64\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 8\nAccuracy: 0.7222222222222222\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 16\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 32\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.01, n_iter: 5000, batch_size: 64\nAccuracy: 0.6296296296296297\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 8\nAccuracy: 0.7222222222222222\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 16\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 32\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.01, n_iter: 10000, batch_size: 64\nAccuracy: 0.6296296296296297\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 8\nAccuracy: 0.7222222222222222\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 16\nAccuracy: 0.7037037037037037\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 32\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.01, n_iter: 20000, batch_size: 64\nAccuracy: 0.6296296296296297\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 8\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 16\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 32\nAccuracy: 0.5925925925925926\nTraining with parameters - lr: 0.1, n_iter: 1000, batch_size: 64\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 8\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 16\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 32\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.1, n_iter: 5000, batch_size: 64\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 8\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 16\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 32\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.1, n_iter: 10000, batch_size: 64\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 8\nAccuracy: 0.6851851851851852\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 16\nAccuracy: 0.6666666666666666\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 32\nAccuracy: 0.6481481481481481\nTraining with parameters - lr: 0.1, n_iter: 20000, batch_size: 64\nAccuracy: 0.6851851851851852\nAccuracy: 0.7777777777777778\nPrecision: 0.6363636363636362\nRecall: 0.7777777777777778\nF1-score: 0.7\n\nAccuracy: 0.7777777777777778 \n\n\nBest parameters: {'lr': 0.01, 'n_iter': 1000, 'batch_size': 8}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}